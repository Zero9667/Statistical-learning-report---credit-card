---
title: "Report Statistical Learning - Credit Card Dataset"
author: "E. Fiorito, R. Licciardello, P. Vivera"
date: "2024-04-03"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

## 0. Introduction to the report

The aim of this report is to perform a statistical analysis, using R, on the dataset "Credit card", uploaded by Rohit Udageri and available on www.kaggle.com.
The training data set is composed of 1,238 observations and 18 variables, with 2 more added on the test data: information about the credit card acceptance and the factors which determines it - among variables such as the type of occupation, the amount of income, the age and so on - are contained. 
The basic idea of the analysis is to build a predictive model on the test set on the basis of the information contained in the training set, capable of describing the possible relationship of dependence between the credit card acceptance - described by the binary variable "acceptance" - and the other factors which will be considered as the predictors of the model.

## 1. Exploratory Data Analysis (EDA)

The exploratory analysis concerns a preliminary overview of the data: the main idea is to get a general understanding of the dataset before performing more complex techniques.
Following this way of thinking, a preliminary process of data cleaning is performed: the aim is to deal with missing data and to make some transformations on the categorical variables in order to make them able to be implemented in a regression model (which requires only numerical variables).

A) Firstly, a set of packages have been downloaded in order to simplify some procedural steps related to the circulation of the R file and the graphical visualization of the results. 

B) The next step is to put in practice the division of the dataset into two subsets: the training data and the test data, with the second one lacking of the target variable "acceptance".

C) Some variables transformation have been performed:
C1) "birthday_count" and "employed_days" are expressed in years by dividing them for 365 and multiplied times -1 as well due to the fact that it is easier to conceive these variables as characterized by positive supports rather than  negative ones.
C2) Two dichotomic variables, "car_owner" and "propert_owner", have been transformed into binary ones due to the fact that their possible modalities, y and n, can be easily associated with 1 and 0.

D) The problem of transformation of the categorical variables into numerical ones is solved through the target encoding procedure, whose basic idea is to calculate the average of the target variable (in this case, "acceptance") for every possible category of the predictors, and to substitute the obtained average values to the original categories as a consequence.

E) The presence of missing values has been identified with respect to two variables: "annual_income" and "birthday_count". There are many approaches to deal with missing values, but the one which will be applied in this case is, for the annual income, the substitution of such values with the average income per category of occupation (expressed by the categorical variable "type_occupation"). Consequently, the missing values for "birthday_count" are substituted with the average values of the age on the basis of the type of annual income.

F) It can be noticed that the data set is strongly unbalanced: this can be evaluated by measuring the proportion of units which assumes value = 0 for the variable "acceptance" (1,098 units, 89% of the units) against the ones which assumes value = 1 for the same output variable (140 units, 11% of the observations). 
The problem will be faced through the usage of the oversampling technique, which solves the issue of incorrect proportion of units attributed to the classes of "acceptance" by artificially creating new observations for the under-represented class (which is the one for which acceptance = 1) which are similar to the ones that already exist. This is done through the implementation of SMOTE (Synthetic Minority Over-sampling Technique).

```{r setup, echo = FALSE , results = 'hide'}
# A 
lib <- c("here","dplyr","ggplot2","GGally","dplyr","ggcorrplot","car","smotefamily","skimr","Metrics","patchwork","boot","MASS")
lapply(lib, library, character.only = TRUE)

# B
training <- read.csv(here("data/processed", "training.csv"))
test<- read.csv(here("data/processed", "test.csv"))
dataset<-training
rownames ( dataset )= dataset [ ,2]
dataset<-dataset[,-2]
dataset<-dataset[,-1]
dataset$acceptance<-dataset$label
dataset<-dataset[,-1]
attach(dataset)

# C1
dataset$Birthday_count<-(dataset$Birthday_count/365)*(-1)
dataset$Employed_days<-(dataset$Employed_days/365)*(-1)

# C2
dataset <- dataset %>%
  group_by(Type_Income) %>%
  mutate(Type_Income_mean = mean(acceptance))

dataset <- dataset %>%
  group_by(GENDER) %>%
  mutate(GENDER_mean = mean(acceptance))

dataset <- dataset %>%
  group_by(EDUCATION) %>%
  mutate(EDUCATION_mean = mean(acceptance))

dataset <- dataset %>%
  group_by(Type_Occupation) %>%
  mutate(Type_Occupation_mean = mean(acceptance))

dataset <- dataset %>%
  group_by(Marital_status) %>%
  mutate(Marital_status_mean = mean(acceptance))

dataset <- dataset %>%
  group_by(Housing_type) %>%
  mutate(Housing_type_mean = mean(acceptance))

# E
variabili_con_null <- names(dataset)[colSums(is.na(dataset)) > 0]
for (i in variabili_con_null) {
  print(i)
  print(sum(is.na(dataset[[i]])))
}

dataset$Annual_income <- ifelse(is.na(dataset$Annual_income),
                                ave(dataset$Annual_income, dataset$Type_Occupation, FUN = function(x) mean(x, na.rm = TRUE)),
                                dataset$Annual_income)

dataset$Birthday_count <- ifelse(is.na(dataset$Birthday_count),
                                 ave(dataset$Birthday_count,dataset$Type_Income, FUN = function(x) mean(x, na.rm=TRUE) ),
                                 dataset$Birthday_count)

# F
variabili_1<-c("acceptance","Type_Income_mean", "GENDER_mean", "EDUCATION_mean", "Type_Occupation_mean", "Marital_status_mean", "Housing_type_mean")
prova<-dataset[,variabili_1]
set.seed(1)
sample <- sample(c(TRUE, FALSE), nrow(prova), replace=TRUE, prob=c(0.7,0.3))
dtrain <- prova[sample, ]
dtest <- prova[!sample, ]
dtrain_balanced <- SMOTE(dtrain,dtrain[,1])
dtrain <- rbind(dtrain,dtrain_balanced$syn_data[,-8])
```
Summary statistics: 

```{r , include = FALSE}
dataset2 <- dataset %>%
  ungroup()

#To remove n_missing and complete_rate, set all base to NULL (not by single points)
my_skim <- skim_with( base = NULL, append = TRUE)
my_skim(dataset2) #Summary statistics using skimr package.
```



Now that the data cleaning process has been completed, it is possible to get a statistical summary and a graphical visualization of the variables.

This is the pie chart that represents the proportion of units characterized by acceptance = 1 with respect to the other ones: as discussed before, this proportion is very low and this leads to a strongly unbalanced data set.

```{r, fig.width=9, fig.height=9, include = FALSE}
counts <- table(dataset$acceptance)
relative_freq <- prop.table(counts)
  pie(counts, edges = 600, col = c("steelblue2", "coral2"), labels = paste(names(counts), " (", round(relative_freq,2),"%, ", counts, " cases )", sep = ""), main = "Pie Chart of Acceptance")
```

Now the graphical visualization of both numerical and categorical variables will be displayed: for both of them, the most appropriate graphic is the barplot, due to the fact that there is interest in looking at the conditional relative frequencies distributions of such variables with respect to the values assumed by "acceptance".

```{r histograms,  fig.width=9, fig.height=9, include = TRUE, echo = FALSE}
#since we want to create an hist of all the numerical variables and not bool, we select only them

dataset_hist <- dataset %>%
  select_if(function(x) is.numeric(x) && any(x > 1))

#It remains variable Housing_type, I remove it and add acceptance ##UPDATE It is not needed since they are ungrouped
#dataset_hist<- subset(dataset_hist, select = -c(Housing_type))

#set the theme for the plots
theme_set(theme_minimal())


#list where the plots will be
plot_hist <- list()
count <- 0
for (column in names(dataset_hist)){
  count <- count + 1
  plot <- ggplot(data = dataset_hist, aes(x = .data[[column]])) +  
    geom_histogram(aes(y = ..count..), alpha = 0.8, fill = "steelblue3", color = "grey70", bins = 30)+
    labs( y = "Frequencies")+
    theme_minimal()
  
  #uncomment if you want to show the plot manually
  #print(plot)
  plot_hist[[paste0("h", count)]] <- plot
}

#plot the combination of graphs, with options
combined_hist <- wrap_plots(plot_hist, ncol= 2) + plot_annotation(title = "Bar plots", theme = theme(plot.title= element_text(color = "steelblue4", size = 18)))

print(combined_hist)
```

It can be noticed how the distribution of Employed_days is characterized by a strong presence of extreme values.

```{r plot categorical preparation, echo = FALSE, include = FALSE}
## Categorical variables

#new list for the new grahs 
plot_cat <- list()
#reset count
count <- 0

#add other graphs, manually added. 
#colors for the graphs
colors <- c("0" = "steelblue3", "1" = "coral3")

#colors for legend
legend_fill <- "grey98"
legend_color <- "grey85"


#Type Income

#add count
count <- count + 1

percentages <- dataset %>%
  group_by(acceptance, Type_Income) %>%
  summarise(count = n()) %>%
  group_by(acceptance) %>%
  mutate(percentage = count / sum(count) * 100)

# Create bar plot

plot <- ggplot(data = percentages, aes(x = Type_Income, y = percentage, fill = as.factor(acceptance))) +
  geom_bar(stat = "identity", position = "dodge", alpha = 1) +
  scale_fill_manual(values = colors) +
  labs(x = "Type of Income", y = "Percentage", fill = "acceptance") +
  theme_minimal()+
  theme(legend.position=c(.12, .80), legend.background = element_rect(fill = legend_fill, color = legend_color))

print(plot)
plot_cat[[paste0("h", count)]] <- plot


#Marital Status
count <- count +1

percentages <- dataset %>%
  group_by(acceptance, Marital_status) %>%
  summarise(count = n()) %>%
  group_by(acceptance) %>%
  mutate(percentage = count / sum(count) * 100)

# Create bar plot
plot <- ggplot(data = percentages, aes(x = Marital_status, y = percentage, fill = as.factor(acceptance))) +
  geom_bar(stat = "identity", position = "dodge", alpha = 1) +
  scale_fill_manual(values = colors) +
  labs(x = "Marital status", y = "Percentage", fill = "acceptance") +
  theme_minimal()+
  theme(legend.position=c(.12, .80), legend.background = element_rect(fill = legend_fill, color = legend_color))


print(plot)
plot_cat[[paste0("h", count)]] <- plot

#Housing_Type
count <- count +1

percentages <- dataset %>%
  group_by(acceptance, Housing_type) %>%
  summarise(count = n()) %>%
  group_by(acceptance) %>%
  mutate(percentage = count / sum(count) * 100)

# Create bar plot
plot <- ggplot(data = percentages, aes(x = Housing_type, y = percentage, fill = as.factor(acceptance))) +
  geom_bar(stat = "identity", position = "dodge", alpha = 1) +
  scale_fill_manual(values = colors) +
  labs(x = "Housing Type", y = "Percentage", fill = "acceptance") +
  theme_minimal()+
  theme(legend.position=c(.12, .80), legend.background = element_rect(fill = legend_fill, color = legend_color))
print(plot)
plot_cat[[paste0("h", count)]] <- plot

#Education 
count <- count +1

percentages <- dataset %>%
  group_by(acceptance, EDUCATION) %>%
  summarise(count = n()) %>%
  group_by(acceptance) %>%
  mutate(percentage = count / sum(count) * 100)

# Create bar plot
plot <- ggplot(data = percentages, aes(x = EDUCATION, y = percentage, fill = as.factor(acceptance))) +
  geom_bar(stat = "identity", position = "dodge", alpha = 1) +
  scale_fill_manual(values = colors) +
  labs(x = "Education", y = "Percentage", fill = "acceptance") +
  theme_minimal()+
  theme(legend.position=c(.12, .80), legend.background = element_rect(fill = legend_fill, color = legend_color))


print(plot)
plot_cat[[paste0("h", count)]] <- plot



#showing the combined graph
combined_cat <- wrap_plots(plot_cat, ncol = 1, heights = c(20, 20, 20, 20), theme(legend.position = "bottom"), guides = "collect") + plot_annotation(title = "Categorical plots by acceptance", subtitle = "proportional percentages for each acceptance value", theme = theme(plot.title= element_text(color = "coral3", size = 18), plot.subtitle = element_text(color = "skyblue4", size = 12)))

```
```{r plot categoricals, fig.width=9, fig.height=9, echo= FALSE}
#showing plots
combined_cat
```

It has to be underlined how the conditional distribution of all the categorical variables is similar is similar with respect to both the two modalities of the variable "acceptance".

Now the correlation between the numerical variables of the dataset with respect to "acceptance" will be evaluated: this step is crucial for the next one, which will be the implementation of a regression model that will try to explain a possible relation of dependence between "acceptance" and the variables of the data set.

```{r corrplot, fig.width=9, fig.height=9, include = TRUE, echo=FALSE}
#keep only numeric variables
dataset_num <- dataset[, sapply(dataset, is.numeric)]
dataset_num <- subset(dataset_num, select= -c(Mobile_phone))
#replace variable names into more readable names
colnames(dataset_num) <- gsub("_", " ", colnames(dataset_num))

cormat <- cor(dataset_num)
#install.packages("ggcorrplot")
library(ggcorrplot)
#to create the new  
ggcorrplot(cormat, type = "full", lab = TRUE, lab_size = 2.3)




## correlation with acceptance bar plot
#determine correlation
## WARNING: You have to re-initialize the dataset each time you redo this part. 
correlations <- cor(dataset_num[, -acceptance], dataset_num[, acceptance])
#sort correlation
sorted_correlations <- sort(correlations, decreasing = TRUE)

#create the plot 
sorted_correlations

###Correlation plot with only acceptance
library(dplyr)
library(tidyr)
# Calculate correlation coefficients
correlation_data <- cor(dataset_num) %>%
  as.data.frame() %>%
  mutate(variable = rownames(.)) %>%
  filter(variable != "acceptance") %>% # Exclude acceptance itself
  rename(correlation = acceptance) %>% # Rename the correlation column
  select(variable, correlation) # Select only relevant columns

# Create the plot
ggplot(correlation_data, aes(x = variable, y = correlation, fill = abs(correlation))) +
  geom_bar(stat = "identity") +
  scale_fill_gradient(low = "coral3", high = "darkblue") +
  coord_flip() +  # Flip coordinates to make it horizontal
  theme_minimal() +
  theme(axis.text.y = element_text(size=10)) +
  labs(
    title = "Correlation coefficients with Acceptance",
    x = "Variables", #since are flipped
    y = "Correlation Coefficient"
  ) +
  guides(fill = FALSE)  # Hide fill legend
```
From the graphical visualization it is possible to see that the most positive-correlated variables - with respect to "acceptance" - are the type of occupation and the housing price; on the other hand, the ownership of a car seems to be the most negative-correlated variable with respect to the acceptance of a credit card.
Finally, other variables seems to have a less significant relationship with the considered target variable.

## 2. Multiple regression analysis

The regression analysis is now implemented. This method, which belongs to the group of supervised statistical learning techniques, aims to build a model capable of explaining the relationship between the target variable (in this case, "acceptance") and a set of predictors (which will be the numerical variables obtained in the EDA) for predictive or inferential aims. In particular, the logistic regression model has been implemented: this particular version of the regression model has been chosen due to the binary nature of the target variable, which would not be fitted very well by the classic linear model, and it provides a specific probabilistic interpretation of the response variable on the basis of the values assumed by the predictors.

The logistic regression model can be seen as a discriminant classifier for the observations: the conditional distribution of the response variable with respect to the predictors is directly estimated through the logistic function. Another alternative approach for classification is the Linear Discriminant Analysis (LDA), which belongs to the category of generative classifiers, works under the assumptions of normal distribution of the units into the classes and homoscedasticity of the classes (i.e. equal covariance matrices) and provides an estimation of the posterior probability for the units to belong to their classes through the imposition of a "decision boundary" as a rule of assignment of each unit to its own class.

Both the two methods have been implemented and their results compared as well.
According to the validation approach, after performing the division of the data set into training and test set (which contain, respectively, the 80% and the remaining 20% of the observations), a second version of the data set has been taken into account due to the unbalanced distribution of the observations.
In particular, an oversampling technique - through the implementation of the SMOTE criterion - has been applied in order to adjust the training set, making the logistic regression model and the LDA easier to be trained. 
Note that the two models have been applied to both the two data sets: the original one (not corrected by the SMOTE procedure) and the corrected one. Given the division of both the two data sets in training set and test set, this means that the models have been applied for a total of four groups of data.
The alternative cross-validation approach, on the other hand, suggests to compute the average mean square errors of the data sets obtained from the removal of a single unit (or k units if the k-folder method is considered) from the original data set: this is done in order to improve the accuracy of the prediction on other sets, since the differences between the results in the training observations and the test ones could be much larger.
Note also that the set of variables which have been considered as the most useful for the regression purpose (i.e., their slopes are statistically significant) has been already selected.

First of all, the training of the models is applied, following both the validation and the cross-validation methods for the application of the models.

```{r glm fitting, include= FALSE}
#here we have all the variable useful for a linear regression

variabili_1<-c("acceptance","Type_Income_mean", "GENDER_mean", "EDUCATION_mean", "Type_Occupation_mean", "Marital_status_mean", "Housing_type_mean")

prova<-dataset[,variabili_1]

#make this example reproducible
set.seed(1)

#use 80% of dataset as training set and 20% as test set
sample <- sample(c(TRUE, FALSE), nrow(prova), replace=TRUE, prob=c(0.8,0.2))
dtrain  <- prova[sample, ]
dtest   <- prova[!sample, ]

# Applying oversampling with SMOTE
dtrain_provisional <- SMOTE(dtrain,dtrain[,1])   
dtrain_b<-rbind(dtrain,dtrain_provisional$syn_data[,-8])  #this include the 80% of the row from the original dataset plus the one created from smote

prova_provisional <- SMOTE(prova,prova[,1])
prova_b<-rbind(prova,prova_provisional$syn_data[,-8]) #this includes every row plus the one created from smote

#Fitting the logistic models
glm_fit_prova<- glm(acceptance ~ ., data = prova, family = binomial(link = "logit"))
glm_fit_prova_b <- glm(acceptance ~ ., data = prova_b, family=binomial)
glm_fit_train<- glm(acceptance ~ ., data = dtrain, family = binomial(link = "logit"))
glm_fit_train_b <- glm(acceptance ~ ., data = dtrain_b, family=binomial)

#Fitting the LDA models

lda_fit_prova<- lda(acceptance ~ ., data = prova, family = binomial(link = "logit"))
lda_fit_prova_b <- lda(acceptance ~ ., data = prova_b, family=binomial)
lda_fit_train<- lda(acceptance ~ ., data = dtrain, family = binomial(link = "logit"))
lda_fit_train_b <- lda(acceptance ~ ., data = dtrain_b, family=binomial)

#Leave one out Cross validation

cv_glm_prova <- cv.glm(prova, glm_fit_prova)  #k=n  
cv_glm_prova_b <- cv.glm(prova_b, glm_fit_prova_b)

```

Now the application on the test sets will be considered for predictive aims.



```{r predictions, include = FALSE, echo = FALSE}
# Test on sample

# Predicting on the test set with logistic regression model
predicted_glm_acceptance <- predict(glm_fit_train, newdata = dtest, type = "response")
predicted_glm_b_acceptance <- predict(glm_fit_train_b, newdata = dtest, type = "response")

# Predicting on the test set with LDA model
predicted_lda_acceptance <- predict(lda_fit_train, newdata = dtest, type = "response")
predicted_lda_b_acceptance <- predict(lda_fit_train_b, newdata = dtest, type = "response")

# Converting probabilities to binary predictions
predicted_glm_acceptance_y  <- ifelse(predicted_glm_acceptance > 0.5, 1, 0)
predicted_glm_b_acceptance_y  <- ifelse(predicted_glm_b_acceptance > 0.5, 1, 0)
predicted_lda_acceptance_y <- predict(lda_fit_train, newdata = dtest)$class
predicted_lda_b_acceptance_y <- predict(lda_fit_train_b, newdata = dtest)$class



#SOLUTION FOR A RANDOM ERROR
predicted_lda_b_acceptance_y <- as.numeric(predicted_lda_b_acceptance_y)
predicted_lda_b_acceptance_y <- predicted_lda_b_acceptance_y-1



# Calculating precision
precision_glm <- Metrics::precision(predicted_glm_acceptance_y, dtest$acceptance)
precision_glm_b <- Metrics::precision(predicted_glm_b_acceptance_y, dtest$acceptance)
precision_lda <- Metrics::precision(predicted_glm_acceptance_y, dtest$acceptance)
precision_lda_b <- Metrics::precision(predicted_lda_b_acceptance_y, dtest$acceptance)
#precision_glm
#precision_glm_b
#precision_lda
#precision_lda_b

# Calculating recall
recall_glm <- Metrics::recall(predicted_glm_acceptance_y, dtest$acceptance)
recall_glm_b <- Metrics::recall(predicted_glm_b_acceptance_y, dtest$acceptance)
recall_lda <- Metrics::recall(predicted_lda_acceptance_y, dtest$acceptance)
recall_lda_b <- Metrics::recall(predicted_lda_b_acceptance_y, dtest$acceptance)
#recall_glm
#recall_glm_b
#recall_lda
#recall_lda_b

# Calculating F1 score
f1_score_glm <- Metrics::f1(predicted_glm_acceptance_y, dtest$acceptance)
f1_score_glm_b <- Metrics::f1(predicted_glm_b_acceptance_y, dtest$acceptance)
f1_score_lda <- Metrics::f1(predicted_lda_acceptance_y, dtest$acceptance)
f1_score_lda_b <- Metrics::f1(predicted_lda_b_acceptance_y, dtest$acceptance)

```

```{r confusion matrices, echo=TRUE, include = TRUE }
table(dtest$acceptance,predicted_glm_acceptance_y)
table(dtest$acceptance,predicted_glm_b_acceptance_y) #with smote 
table(dtest$acceptance,predicted_lda_acceptance_y)
table(dtest$acceptance,predicted_lda_b_acceptance_y) #with smote
```

```{r F1 scores, echo=TRUE, include=TRUE}

f1_score_glm
f1_score_glm_b
f1_score_lda
f1_score_lda_b
```

Since the results of the logistic regression should be interpreted in probabilistic terms, it can be said that a change in the type of occupation is the most determinant factor in the decision of accepting or not a credit card according to the data.
However, the model seems to be not so precise: according to the precision index, applying the model on the test set means to be able to correctly predict just the 20% of the values for every observation. On the other hand, the F1 score can be approximated to 1, counter-balancing the negative response of the prediction.